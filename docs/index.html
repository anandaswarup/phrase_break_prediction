<!DOCTYPE html>
<html>

<head>
    <link rel="stylesheet" type="text/css" href="style.css">
    <title>Phrase break prediction for Text-to-Speech Systems</title>
</head>

<body>

    <h1>Phrase break prediction for Text-to-Speech Systems</h1>
    <p>
        This page contains synthesized audio samples of children's stories to accompany the repository
        <a href="https://github.com/anandaswarup/phrase_break_prediction">anandaswarup/phrase_break_prediction</a>
        which contains code to train speaker independent phrasing models for English Text-to-Speech systems. In text,
        phrase breaks are usually represented by punctuation. Typically, Text-to-Speech systems insert phrase breaks in
        the synthesized speech whenever they encounter a comma in the text to be synthesized.
        <br>
        <br>
        Currently the codebase supports two models
    <ol>
        <li>
            BLSTM token classification model using task specific word embeddings trained from scratch
        </li>
        <li>
            Fine tuned BERT model with a token classification head
        </li>
    </ol>
    Given unpunctuated text as input, these models punctuate the text with commas, and the text with predicted commas is
    then passed to the Text-to-Speech system to be synthesized. The models are trained using LibriTTS alignments
    provided at <a href="https://github.com/kan-bayashi/LibriTTSLabel">kan-bayashi/LibriTTSLabel</a>. The
    train-clean-360 split is used for training, while the dev-clean and test-clean splits are used for validation and
    test respectively.
    </p>
    <p>
        The samples presented in this page are synthesized from text using the End-to-End TTS system based on the
        Tacotron2
        model with modifications as described below
    <ol>
        <li>
            A Tacotron2 model with Dynamic Convolutional Attention which modifies the hybrid location sensitive
            attention mechanism to be purely location based, resulting in better generalization on long utterances. This
            model takes text (in the form of character sequence) as input and predicts a sequence of mel-spectrogram
            frames as output.
        </li>
        <li>
            A WaveRNN based vocoder; which takes the mel-spectrogram predicted in the previous step as input and
            generates a waveform as output.
        </li>
    </ol>
    The End-to-End TTS system has been trained on the <a href="https://keithito.com/LJ-Speech-Dataset/">LJSpeech
        dataset</a>. Code for training the TTS system can be found at <a
        href="https://github.com/anandaswarup/TTS">anandaswarup/TTS</a>
    <br>
    <br>
    In all samples presented below, no phrasing refers to unpunctuated text synthesized by the TTS system described
    above, while blstm and bert refers to text punctuated using the blstm and bert models respectively and then
    synthesized by the TTS system.
    </p>

</body>

</html>